
import torch
import os
import glob
import numpy as np
import json
import torch.utils.data
import torchvision
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import shutil
import ultralytics
import cv2
os.environ['YOLO_VERBOSE'] = 'false'
from ultralytics import YOLO # type: ignore
from sklearn.model_selection import train_test_split
import yaml

def calculatePredictBox(result):
    
    """
    **Collects information defining a bounding box from a model prediction result.**

    Parameters:

        result (ultralytics.engine.results.Results): A model prediction result.

    Returns:
    
        output (dict): A dictionary containing important information with keys. See predict_box below.
    """

    # Collect information from result
    img_height, img_width = result.orig_shape

    x_min = result.boxes.xyxy[0][0]
    y_min = result.boxes.xyxy[0][1]
    x_max = result.boxes.xyxy[0][2]
    y_max = result.boxes.xyxy[0][3]
    x_center = result.boxes.xywh[0][0]
    y_center = result.boxes.xywh[0][1]
    box_width = result.boxes.xywh[0][2]
    box_height = result.boxes.xywh[0][3]

    # Output dictionary
    predict_box = {
        "path": result.path, # Path to image file
        "x_min": x_min, # X value of top left corner of bounding box
        "y_min": y_min, # Y value of top left corner of bounding box
        "x_max": x_max, # X value of bottom right corner of bounding box
        "y_max": y_max, # Y value of bottom right corner of bounding box
        "x_center": x_center, # X value of center of bounding box
        "y_center": y_center, # Y value of center of bounding box
        "box_width": box_width, # Width of bounding box
        "box_height": box_height, # Height of bounding box
        "img_width": img_width, # Width of image
        "img_height": img_height # Height of image
    }

    return predict_box


def calculateSquareBox(box, adjust = "Vertical"):

    """
    **Converts a rectanglular bounding box to a square bounding box.**

    Change adjust parameter to change how the square is defined.

    Parameters:
        box (dict): Dictionary with information of a bounding box generated by calculatePredictBox() or calculateTruthBox(). View these functions to view dictionary structure.

        adjust (str): String with expected values. Controls how the square is defined from bounding box.
        
            "Horizontal": Crops or expands from the left side and right side of the bounding box equally to match the width with the height.

            "Left": Crops or expands from the left side of the bounding box to match the width with the height.

            "Right": Crops or expands from the right side of the bounding box to match the width with the height.

            "Vertical": Crops or expands from the top and the bottom of the bounding box equally to match the height with the width.

            "Top": Crops or expands from the top of the bounding box to match the height with the width.

            "Bottom": Crops or expands from the bottom of the bounding box to match the height with the width.

            "None": Bypasses this function, returns original bounding box without error message.

            Other values: Returns original bounding box with an error message.

    Returns:
        output (dict): Dictionary with updated square bounding box information. Remains in same structure as original box.
    
        Returns original dictionary if "adjust" parameter has an unexpected value or if the bounding box was already square.

    """
    # Load information from dictionary as temporary variables
    x_min = box["x_min"]
    y_min = box["y_min"]
    box_width = box["box_width"]
    box_height = box["box_height"]
    img_width = box["img_width"]
    img_height = box["img_height"]

    # Check if the bounding box is square. Returns original dictionary if true.
    if box_height == box_width:
        print("Image already square!. Image path: {}".format(box["path"]))
        return box      
    
    # Base value to be adjusted 
    adjust_num = abs(box_width - box_height)/2

    # Check if adjust has unexpected value. Returns original dictionary if true.
    if adjust not in ["Horizontal", "Vertical", "Top", "Bottom", "Left", "Right", "None"]:
        print("Unexpected value for adjust parameter! Conversion abandoned. Image path: {}".format(box["path"]))
        return box
    
    if adjust == "None":
        return box
    
    if adjust == "Horizontal": # Change width to match height, crop/expand from left side and right side of bounding box equally
        if box_width > box_height: 
            # Crop
            new_x_min = x_min + adjust_num
            new_y_min = y_min
            new_box_width = box_height
            new_box_height = box_height
        else: 
            # Expand
            new_x_min = x_min - adjust_num
            new_y_min = y_min
            new_box_width = box_height
            new_box_height = box_height

    if adjust == "Left": # Change width to match height, crop/expand from left side of bounding box
        if box_width > box_height: 
            # Crop
            new_x_min = x_min + 2*adjust_num
            new_y_min = y_min
            new_box_width = box_height
            new_box_height = box_height
        else: 
            # Expand
            new_x_min = x_min - 2*adjust_num
            new_y_min = y_min
            new_box_width = box_height
            new_box_height = box_height

    if adjust == "Right": # Change width to match height, crop/expand from right side of bounding box
        # Crop / Expand
        new_x_min = x_min
        new_y_min = y_min
        new_box_width = box_height
        new_box_height = box_height

    if adjust == "Vertical": # Change height to match width, crop/expand from top and bottom of bounding box equally
        if box_height > box_width:
            # Crop
            new_x_min = x_min 
            new_y_min = y_min + adjust_num
            new_box_width = box_width
            new_box_height = box_width
        else: 
            # Expand
            new_x_min = x_min 
            new_y_min = y_min - adjust_num
            new_box_width = box_width
            new_box_height = box_width

    if adjust == "Top": # Change height to match width, crop/expand from top of bounding box
        if box_height > box_width:
            # Crop
            new_x_min = x_min 
            new_y_min = y_min + 2*adjust_num
            new_box_width = box_width
            new_box_height = box_width
        else: 
            # Expand
            new_x_min = x_min 
            new_y_min = y_min - 2*adjust_num
            new_box_width = box_width
            new_box_height = box_width

    if adjust == "Bottom": # Change height to match width, crop/expand from bottom of bounding box
        # Crop / Expand
        new_x_min = x_min 
        new_y_min = y_min 
        new_box_width = box_width
        new_box_height = box_width
    
    # Calculate the bottom right corner of the bounding box
    new_x_max = new_x_min + new_box_width
    new_y_max = new_y_min + new_box_height

    # Checks if any values of the top left and the bottom right corners exceed the range of the original image
    # Adjust the value to the maximum and minimum within the image if any value exceeds, and displays a error message
    # Updates all values of the original dictionary
    invalid_report = 0

    box["x_min"] , invalid_report = (new_x_min , invalid_report) if  new_x_min >= 0 else (0 , invalid_report + 1)
    box["y_min"] , invalid_report = (new_y_min , invalid_report) if  new_y_min >= 0 else (0 , invalid_report + 1)
    box["x_max"] , invalid_report = (new_x_max , invalid_report) if  new_x_max <= img_width else (img_width , invalid_report + 1)
    box["y_max"] , invalid_report = (new_y_max , invalid_report) if  new_y_max <= img_height else (img_height , invalid_report + 1)

    if invalid_report > 0:
        print("The final image will not be square as the calculated square exceeds image range.")
    
    # Calculate and update remaining values in original dictionary
    box["x_center"] = (box["x_min"] + box["x_max"])/2
    box["y_center"] = (box["y_min"] + box["y_max"])/2
    box["box_width"] = box["x_max"] - box["x_min"]
    box["box_height"] = box["y_max"] - box["y_min"]

    return box


def calculateTruthBox(result, txt_dir, img_width, img_height):
    
    """
    **Collects and calculates information defining a bounding box from the ground truth.**

    The corresponding text files containing the ground truth should have the same file name as the image, and located in the text directory.

    Image width and height are required for scaling normalised values in the YOLO text file.


    Parameters:

        result (ultralytics.engine.results.Results): A model prediction result.

        txt_dir (str): The directory for your ground truth text files.

        img_width (float):  The width of the original image.

        img_height (float): The height of the original image.

    Returns:
    
        output (dict):  A dictionary containing important information with keys. See truth_box below.
    """
    import os

    # Find the corresponding ground truth text file 
    file_dir_path = os.path.splitext(result.path)[0]
    file_name = file_dir_path.split(os.sep)[-1]
    txt_file = os.sep.join([txt_dir, file_name +".txt"])

    # Retrieve information from text file
    with open(txt_file, "r") as file:
        info = file.read()
        values = info.split()
        x_min = float(values[1]) * img_width
        y_min = float(values[2]) * img_height
        x_max = float(values[3]) * img_width
        y_max = float(values[6]) * img_height

        # Calculate other information
        x_center = (x_min + x_max)/2
        y_center = (y_min + y_max)/2
        box_width = x_max - x_min
        box_height = y_max - y_min

    # Output dictionary
    truth_box = {
        "path": txt_file, # Path to text file
        "file_name": file_name, # Base file name of the text / image
        "x_min": x_min, # X value of top left corner of bounding box
        "y_min": y_min, # Y value of top left corner of bounding box
        "x_max": x_max, # X value of bottom right corner of bounding box
        "y_max": y_max, # Y value of bottom right corner of bounding box
        "x_center": x_center, # X value of center of bounding box
        "y_center": y_center, # Y value of center of bounding box
        "box_width": box_width, # Width of bounding box
        "box_height": box_height, # Height of bounding box
        "img_width": img_width, # Width of image
        "img_height": img_height # Height of image

    }

    return truth_box


def createYaml(path, train, val, nc, names, output_dir):

    """
    **Creates a .yaml file based on given information.**

    The folders for labels are automatically detected, hence input is unnecessary.

    Parameters:

        path (str): The path to the YOLO dataset folder.

        train (str): The relative path from the YOLO dataset folder to the training images.

        val (str): The relative path from the YOLO dataset folder to the validation images.

        nc (int): The number of classes of bounding boxes.

        names ([str, ...]): The names of classes of bounding boxes.

        output_dir (str): The directory for storing output files.

    Returns:
        output: None
    """

    yamldata = {
    "path": path,
    "train": train,
    "val": val,
    "nc": nc,
    "names": names
    }
    # Write data to .yaml file
    with open(output_dir + "/data.yaml", 'w') as temp_file:
        yaml.dump(yamldata, temp_file, sort_keys=False)


def extraResultPlots(json_file):

    """
    **Generates additional plots based on provided .json file from trainModel().**

    Parameters:

        json_file (YOLO model): The path to your .json file.

    Returns:
        output: None
    """

    with open(json_file) as load_file:
        temp_json = json.load(load_file)
        print(temp_json)
        epoch_num = temp_json["Epoch Number"]
        temp_json.pop("Epoch Number")
        plt.figure(figsize=(32,40))
        for index, key in enumerate(temp_json.keys()):
            plt.subplot(5,5,index+1)
            plt.plot(epoch_num,temp_json[key],marker = "o")
            plt.title(key)
        print(len(temp_json))
    
    plt.show()


def folderCompiler(input_dir, output_dir, target_suffix, num_dir = 0):

    """
    **Copies target files from a directory, and saves the files into a specific directory.**


    Parameters:

        input_dir (str): The directory containing your files.

        output_dir (str): The directory for saving the target files.

        target_suffix (str): The common suffix for your target files. This string starts with the targetting file format (".png"), and extra information can be added ("_C.png")

        num_dir (int): The number of folders included before the output file. Default: 0

    Returns:
    
        output: None.
    """
    root, dirs, files = os.walk(input_dir)
    print(root, dirs, files)
    for root, dirs, files in os.walk(input_dir):
       print(root)
       for file in files:
            print(file)
            if file.endswith(target_suffix):
                print("Target found") 
                file_path = os.path.join(root, file)
                print(file_path)
                sub_path = os.sep.join(file_path.split(os.sep)[-num_dir-1:])
                print(sub_path)
                print(file_path.split(os.sep)[-1:])
                os.makedirs(os.path.join(output_dir, os.path.dirname(sub_path)), exist_ok=True)
                shutil.copy(file_path, os.path.join(output_dir, os.path.dirname(sub_path)))


def inferenceCheck(model, img_files, showImages = False):

    """
    **Passes inference images through the trained YOLO model for evaluation.**

    Should be combined with other functions to analyze results.

    Parameters:

        model (model): <class 'ultralytics.models.yolo.model.YOLO'> Loaded model.

        img_files ([img_file, ...]): A list of inference images.

        showImages (bool): If true, all images with auto-generated bounding box with be shown in indivdual windows. Default: False

    Returns:
        output ([ultralytics.engine.results.Results, ...]): A list of result data from the model.
    """

    # Collects all inference images provided as PIL images and filter out all other files
    img_list = []
    for file in img_files:
        if file.endswith(".png"):
            img_list.append(Image.open(file))

    # Predicts bounding boxes with provided model for all images
    results = model(img_list)

    # Display all images in seperate windows if showImages is True
    if showImages:
        for result in results:
            result.show()        

    return results


def LMtoYOLO(json_file, output_dir):

    """
    **Converts rectangular bounding boxes in LabelMe .json files to YOLO required segmentation.**

    The folders for labels are automatically detected, hence input is unnecessary.

    Parameters:

        json_file (str): The path to the .json file containing rectangular bounding boxes coordinates.

        output_dir (str): The directory for storing output files.

    Returns:
        output: None
    """
    with open(json_file) as load_file:
        temp_json = json.load(load_file)
        
    # Obtaining bounding box coordinates from LabelMe .json file
    x_min = min(temp_json['shapes'][0]['points'][0][0], temp_json['shapes'][0]['points'][1][0])
    y_min = min(temp_json['shapes'][0]['points'][0][1], temp_json['shapes'][0]['points'][1][1])
    x_max = max(temp_json['shapes'][0]['points'][0][0], temp_json['shapes'][0]['points'][1][0])
    y_max = max(temp_json['shapes'][0]['points'][0][1], temp_json['shapes'][0]['points'][1][1])
    full_width = temp_json['imageWidth']
    full_height = temp_json['imageHeight']

    print(x_min, y_min, x_max, y_max, full_width, full_height)

    # Normalising coordinates
    x_min_normal = x_min / full_width
    y_min_normal = y_min / full_height
    x_max_normal = x_max / full_width
    y_max_normal = y_max / full_height

    print(x_min_normal, y_min_normal, x_max_normal, y_max_normal)

    # The number the bounding box class belongs to
    class_num = 0

    # The information required for the .txt file
    txt_info = "{} {} {} {} {} {} {} {} {}".format(class_num, x_min_normal, y_min_normal, x_max_normal, y_min_normal, x_max_normal, y_max_normal, x_min_normal, y_max_normal)

    # Write the .txt files
    temp_path = []
    base_filename = os.path.splitext(json_file)[0]
    temp_path = base_filename.split(os.sep)[:]
    output_path = os.path.join(output_dir,temp_path[-1])
    print(base_filename)
    print(output_path)
    with open(str(output_path) + ".txt", 'w') as txt_file:
        txt_file.write("{}".format(txt_info))


def manualDice(box_A, box_B):

    """
    **Calculates the dice coefficient of a prediction from the prediction and the ground truth.**

    Parameters:
        box_A, box_B (dict): Dictionaries containing information about a bounding box generated by calculatePredictBox() or calculateTruthBox().
        
    Returns:
        output (float): The dice coefficient of the prediction.

    """    
    # Retrieve information
    A_x_min = box_A["x_min"]
    A_y_min = box_A["y_min"]
    A_x_max = box_A["x_max"]
    A_y_max = box_A["y_max"]

    B_x_min = box_B["x_min"]
    B_y_min = box_B["y_min"]
    B_x_max = box_B["x_max"]
    B_y_max = box_B["y_max"]

    # Pinpoint intersection area
    I_x_min = max(A_x_min,B_x_min)
    I_y_min = max(A_y_min,B_y_min)
    I_x_max = min(A_x_max,B_x_max)
    I_y_max = min(A_y_max,B_y_max)

    # Detect if intersection non-existent. Prevents negative values and calculation errors
    if I_x_max <= I_x_min or I_y_max <= I_y_min:
        print("There is no intersection!")
        return None
    
    # Calculates dice coefficient
    intersect = (I_x_max - I_x_min)*(I_y_max - I_y_min)
    areaA = (A_x_max - A_x_min)*(A_y_max - A_y_min)
    areaB = (B_x_max - B_x_min)*(B_y_max - B_y_min)
    dice = 2 * intersect / (areaA + areaB)

    return dice


def manualIoU(box_A, box_B):

    """
    **Calculates the intersection over union value of a prediction from the prediction and the ground truth.**

    Parameters:
        box_A, box_B (dict): Dictionaries containing information about a bounding box generated by calculatePredictBox() or calculateTruthBox().
        
    Returns:
        output (float): The intersection over union value of the prediction.

    """   
    # Retrieve information
    A_x_min = box_A["x_min"]
    A_y_min = box_A["y_min"]
    A_x_max = box_A["x_max"]
    A_y_max = box_A["y_max"]

    B_x_min = box_B["x_min"]
    B_y_min = box_B["y_min"]
    B_x_max = box_B["x_max"]
    B_y_max = box_B["y_max"]

    # Pinpoint intersection area
    I_x_min = max(A_x_min,B_x_min)
    I_y_min = max(A_y_min,B_y_min)
    I_x_max = min(A_x_max,B_x_max)
    I_y_max = min(A_y_max,B_y_max)

    # Detect if intersection non-existent. Prevents negative values and calculation errors
    if I_x_max <= I_x_min or I_y_max <= I_y_min:
        print("There is no intersection!")
        return None
    
    # Calculates dice coefficient
    intersect = (I_x_max - I_x_min)*(I_y_max - I_y_min)
    union = (A_x_max - A_x_min)*(A_y_max - A_y_min) + (B_x_max - B_x_min)*(B_y_max - B_y_min) - intersect
    IoU = intersect / union

    return IoU


def manual_mAP(IoU_list):

    """
    **Calculates mAP50 and mAP50-95 values from a list of intersection over union(IoU) values.**

    Parameters:
        IoU_list ([float, ...]]): A list of IoU floats.

    Returns:
        output (float_mAP50, float_mAP50_95): The mAP50 and mAP50_95 values.

    """
    # Assign rank values for each IoU values
    rank_list = []
    for IoU in IoU_list:
        rank = 0
        if IoU <= 0.50:
            rank = 0
        elif IoU <= 0.55:
            rank = 1
        elif IoU <= 0.60:
            rank = 2
        elif IoU <= 0.65:
            rank = 3
        elif IoU <= 0.70:
            rank = 4
        elif IoU <= 0.75:
            rank = 5
        elif IoU <= 0.80:
            rank = 6
        elif IoU <= 0.85:
            rank = 7
        elif IoU <= 0.85:
            rank = 8
        elif IoU <= 0.85:
            rank = 9
        else:
            rank = 10
        rank_list.append(rank)

    # Calculate mAP50 based on amount of non-zeros 
    mAP50 = (len(rank_list) - rank_list.count(0)) / len(rank_list)

    # Calculate mAP50_95 based on assigned rank values
    mAP50_95 = sum(rank_list) * 0.1 / len(rank_list)

    return mAP50, mAP50_95


def metric_tally(trainer):

    """
    **Collects information during model training and saves data as a .json file. Outputs progress occasionally in a different text file.**

    Should be called and used exclusively by trainModel().

    Parameters:
        trainer (ultralytics.models.yolo.segment.train.SegmentationTrainer): The trainer responsible for training the current model.

    Returns:
        output: None
    """

    global epoch_num_global, epoch_count, out_dir, result_dict, epochMod

    epoch_count += 1
    final_epoch = False

    if epoch_count == 1: # Initializing tally and output
        result_dict = {
        "Epoch Number": [],
        "Best Fitness": [],
        "Box Loss": [],
        "Lowest Box Loss": [],
        "Seg Loss": [],
        "Lowest Seg Loss": [],
        "Cls Loss": [],
        "Lowest Cls Loss": [],
        "Dfl Loss": [],
        "Lowest Dfl Loss": [],
        "Box Precision": [],
        "Highest Box Precision": [],
        "Box Recall": [],
        "Highest Box Recall": [],
        "Box mAP50": [],
        "Highest Box mAP50": [],
        "Box mAP50-95": [],
        "Highest Box mAP50-95": [],
        "Mask Precision": [],
        "Highest Mask Precision": [],
        "Mask Recall": [],
        "Highest Mask Recall": [],
        "Mask mAP50": [],
        "Highest Mask mAP50": [],
        "Mask mAP50-95": [],
        "Highest Mask mAP50-95": []
        }

        txt_file = open(out_dir + "/custom_output.txt", 'w')
        os.startfile(out_dir + "\\custom_output.txt")
        txt_startup = "Custom output file initiated.\nThis text file is stored at: " + out_dir + "/custom_output.txt\nWarning: Running trainNewModel() again will delete all contents in this file!\nIf you are viewing this file using Notepad, you may have to minimize and maximize the window to see live outputs.\n\n"
        txt_file.write(txt_startup)
    else:
        txt_file = open(out_dir + "/custom_output.txt", 'a')

        result_dict["Epoch Number"].append(epoch_count)
        result_dict["Best Fitness"].append(trainer.best_fitness) if trainer.best_fitness != None else result_dict["Best Fitness"].append(0)
        result_dict["Box Loss"].append(trainer.metrics["val/box_loss"])
        result_dict["Seg Loss"].append(trainer.metrics["val/seg_loss"])
        result_dict["Cls Loss"].append(trainer.metrics["val/cls_loss"])
        result_dict["Dfl Loss"].append(trainer.metrics["val/dfl_loss"])
        result_dict["Lowest Box Loss"].append(min(result_dict["Box Loss"]))
        result_dict["Lowest Seg Loss"].append(min(result_dict["Seg Loss"]))
        result_dict["Lowest Cls Loss"].append(min(result_dict["Cls Loss"]))
        result_dict["Lowest Dfl Loss"].append(min(result_dict["Dfl Loss"]))
        result_dict["Box Precision"].append(trainer.metrics["metrics/precision(B)"])
        result_dict["Box Recall"].append(trainer.metrics["metrics/recall(B)"])
        result_dict["Box mAP50"].append(trainer.metrics["metrics/mAP50(B)"])
        result_dict["Box mAP50-95"].append(trainer.metrics["metrics/mAP50-95(B)"])
        result_dict["Highest Box Precision"].append(max(result_dict["Box Precision"]))
        result_dict["Highest Box Recall"].append(max(result_dict["Box Recall"]))
        result_dict["Highest Box mAP50"].append(max(result_dict["Box mAP50"]))
        result_dict["Highest Box mAP50-95"].append(max(result_dict["Box mAP50-95"]))
        result_dict["Mask Precision"].append(trainer.metrics["metrics/precision(M)"])
        result_dict["Mask Recall"].append(trainer.metrics["metrics/recall(M)"])
        result_dict["Mask mAP50"].append(trainer.metrics["metrics/mAP50(M)"])
        result_dict["Mask mAP50-95"].append(trainer.metrics["metrics/mAP50-95(M)"])
        result_dict["Highest Mask Precision"].append(max(result_dict["Mask Precision"]))
        result_dict["Highest Mask Recall"].append(max(result_dict["Mask Recall"]))
        result_dict["Highest Mask mAP50"].append(max(result_dict["Mask mAP50"]))
        result_dict["Highest Mask mAP50-95"].append(max(result_dict["Mask mAP50-95"]))
         
    if epoch_count == epoch_num_global:
        final_epoch = True
        txt_file.write("Final Epoch Training Completed!\n")

    if epoch_count % epochMod == 0 or final_epoch == True:
       
       txt_info = "Epoch {} Completed.\n".format(epoch_count)

       for key in result_dict.keys():
            txt_info += key + ": {:.5f}\t".format(result_dict[key][epoch_count-2])

       txt_info += "\n\n"
       txt_file.write(txt_info)

       if final_epoch == True:
           txt_file.write("Training results saved at: {}\n".format(trainer.save_dir))
           txt_file.write("Best Checkpoint saved at: {}\n".format(trainer.best))
           txt_file.write("Device used for training: {}\n".format(trainer.device))
           with open(out_dir + "/output_data.json", "w") as json_file:
               json.dump(result_dict, json_file)
               txt_file.write("Results dictionary saved as: " + out_dir + "/output_data.json")
               

def metric_tally_silent(trainer):

    """
    **Collects information during model training and saves data as a .json fil without creating and outputting in a text file.**

    Should be called and used exclusively by trainModel().

    Parameters:
        trainer (ultralytics.models.yolo.segment.train.SegmentationTrainer): The trainer responsible for training the current model.

    Returns:
        output: None
    """
    global epoch_num_global, epoch_count, out_dir, result_dict

    epoch_count += 1

    if epoch_count == 1: # Initializing tally
        result_dict = {
        "Epoch Number": [],
        "Best Fitness": [],
        "Box Loss": [],
        "Lowest Box Loss": [],
        "Seg Loss": [],
        "Lowest Seg Loss": [],
        "Cls Loss": [],
        "Lowest Cls Loss": [],
        "Dfl Loss": [],
        "Lowest Dfl Loss": [],
        "Box Precision": [],
        "Highest Box Precision": [],
        "Box Recall": [],
        "Highest Box Recall": [],
        "Box mAP50": [],
        "Highest Box mAP50": [],
        "Box mAP50-95": [],
        "Highest Box mAP50-95": [],
        "Mask Precision": [],
        "Highest Mask Precision": [],
        "Mask Recall": [],
        "Highest Mask Recall": [],
        "Mask mAP50": [],
        "Highest Mask mAP50": [],
        "Mask mAP50-95": [],
        "Highest Mask mAP50-95": []
        }

    else:  # Saves data of each epoch into dictionaary. Ignore first epoch as most values are 0.
        result_dict["Epoch Number"].append(epoch_count)
        result_dict["Best Fitness"].append(trainer.best_fitness) if trainer.best_fitness != None else result_dict["Best Fitness"].append(0)
        result_dict["Box Loss"].append(trainer.metrics["val/box_loss"])
        result_dict["Seg Loss"].append(trainer.metrics["val/seg_loss"])
        result_dict["Cls Loss"].append(trainer.metrics["val/cls_loss"])
        result_dict["Dfl Loss"].append(trainer.metrics["val/dfl_loss"])
        result_dict["Lowest Box Loss"].append(min(result_dict["Box Loss"]))
        result_dict["Lowest Seg Loss"].append(min(result_dict["Seg Loss"]))
        result_dict["Lowest Cls Loss"].append(min(result_dict["Cls Loss"]))
        result_dict["Lowest Dfl Loss"].append(min(result_dict["Dfl Loss"]))
        result_dict["Box Precision"].append(trainer.metrics["metrics/precision(B)"])
        result_dict["Box Recall"].append(trainer.metrics["metrics/recall(B)"])
        result_dict["Box mAP50"].append(trainer.metrics["metrics/mAP50(B)"])
        result_dict["Box mAP50-95"].append(trainer.metrics["metrics/mAP50-95(B)"])
        result_dict["Highest Box Precision"].append(max(result_dict["Box Precision"]))
        result_dict["Highest Box Recall"].append(max(result_dict["Box Recall"]))
        result_dict["Highest Box mAP50"].append(max(result_dict["Box mAP50"]))
        result_dict["Highest Box mAP50-95"].append(max(result_dict["Box mAP50-95"]))
        result_dict["Mask Precision"].append(trainer.metrics["metrics/precision(M)"])
        result_dict["Mask Recall"].append(trainer.metrics["metrics/recall(M)"])
        result_dict["Mask mAP50"].append(trainer.metrics["metrics/mAP50(M)"])
        result_dict["Mask mAP50-95"].append(trainer.metrics["metrics/mAP50-95(M)"])
        result_dict["Highest Mask Precision"].append(max(result_dict["Mask Precision"]))
        result_dict["Highest Mask Recall"].append(max(result_dict["Mask Recall"]))
        result_dict["Highest Mask mAP50"].append(max(result_dict["Mask mAP50"]))
        result_dict["Highest Mask mAP50-95"].append(max(result_dict["Mask mAP50-95"]))
         
    if epoch_count == epoch_num_global:
        with open(out_dir + "/output_data.json", "w") as json_file:
            json.dump(result_dict, json_file)
            print("Results dictionary saved as: " + out_dir + "/output_data.json")


def plotBoundingBox(x_min, y_min, box_width, box_height, subplot, customcolor = "k"):

    """
    **Plots a bounding box from the provided information directly onto the specified matplotlib subplot.**

    Patches.rectangle requires the data to be in CPU. Tensor should be converted to float beforehand.

    Parameters:

        x_min (float): float. The X value of top left corner of the bounding box.

        y_min (float): float. The Y value of top left corner of the bounding box.

        box_width (float): float. The width of the bounding box.

        box_height (float): float. The height of the bounding box.

        subplot (matplotlib subplot): The subplot that the bounding box should be plotted on.

        customcolor (str): The color of the bounding box. Follows color formats from matplotlib. Default color: black.


    Returns:
    
        output: None.
    """
    from matplotlib import patches

    # Combine x_min and y_min into a tuple as required by patches.Rectangle
    anchor_point = (x_min, y_min)

    # Create Rectangle Patches object
    Rectangle = patches.Rectangle(anchor_point, box_width, box_height, linewidth = 1, edgecolor = customcolor, fill = False)

    # Plot rectangle into subplot
    subplot.add_patch(Rectangle)       

    return None
        

def trainModel(dataset_dir, model_path = None, epoch_num = 100, simple_output = True, s_out_per_epoch = 10):
        
    """
    **Trains a model based on provided YOLO Dataset.**

    The model will be trained with (epoch_num) epochs. Leave model_path to train a brand new "yolo11n-seg.pt" model.

    You can choose to open a simpler output system recorded on a newly generated text file. Use s_out_per_epoch to control the amount of outputs.

    Parameters:
        dataset_dir (str): The target YOLO dataset. This directory should include images, labels and a .yaml file.

        model_path (str): The target model to be trained. The model should be in ".pt" format. Input None to train new "yolo11n-seg.pt" model. Default: None

        epoch_num (int): Number of epochs used for training. Default: 100

        simple_output (bool): Whether to create and open a text file to output statistics. Default: True

        s_out_per_epoch (int): Number of epochs before an output in the simple output system. Ignored if simple_output = False. Default: 10

    Returns:
        output: None
    """

    global out_dir, epochMod, epoch_count, epoch_num_global

    epoch_count = 0
    epochMod = s_out_per_epoch 
    out_dir = dataset_dir
    epoch_num_global = epoch_num

    if model_path == None:
        model = YOLO("yolo11n-seg.pt", verbose = False)
    else:
        model = YOLO(str(model_path), verbose = False)

    if simple_output:
        model.add_callback("on_train_epoch_end", metric_tally)
    else:
        model.add_callback("on_train_epoch_end", metric_tally_silent)

    model.train(data = dataset_dir + "/data.yaml", epochs=epoch_num, verbose = False)

    print("Training complete!")


def validateModel(model, yaml_path):

    """
    **Run a validation check on a trained model with a new YOLO dataset.**

    Parameters:

        model (YOLO model): Loaded model.

        yaml.path (str): The path to your dataset .yaml file.

    Returns:
        output ([ultralytics.engine.results.Results, ...]): A list of result data from the model.
    """

    val_results = model.val(data = yaml_path)
    return val_results


def YOLOTTSplit(image_dir = None, txt_dir = None, target_dir = None, test_section = 0.20):
    
    """
    **Splits images and corresponding text to training and testing sets, and automatically compiles files into YOLO required format.**

    Please make sure all images and their corresponding text files have the same filename!

    Parameters:

        image_dir (str): The directory to your images.

            Your images should be stored as: "image_dir/Your Images"

            
        txt_dir (str): The directory to your text files.

            Your text files should be stored as: "txt_dir/Your Text Files"

        target_dir (str): The directory for outputting files.

            The training images will be saved as: "target_dir/images/train/Training Images"

            The testing images will be saved as: "target_dir/images/val/Training Images" 
        
            The training text files will be saved as: "target_dir/labels/train/Training Text Files"

            The testing text files will be saved as: "target_dir/labels/val/Testing Text Files" 
        
        test_section (float): The percentage of images and labels to be used for testing/validating. Default: 0.20
            
    Returns:
    
        output: None

    """

    # Check if any directories are missing, prevent errors
    if image_dir == None or txt_dir == None or target_dir == None:
        print("YOLOTTSplit: One or more required directories are missing!")

        # End function if above error occurs
        return None
    
    # Retrieve files from provided input directories
    image_dir_files = glob.glob("./" + image_dir + "/**")
    txt_dir_files = glob.glob("./" + txt_dir + "/**")

    # Create empty arrays 
    img_array = []
    txt_array = []

    # Combines all image file names into a 2-D array
    for file in image_dir_files:
        if file.endswith(".png"):
          img_array.append([file.split(os.sep)[-1]])

    # Combines all text file names into a 2-D array
    for file in txt_dir_files:
        if file.endswith(".txt"):
          txt_array.append([file.split(os.sep)[-1]])

    # Check if any directories are missing, prevent errors
    if len(img_array) != len(txt_array):
       print("YOLOTTSplit: Amount of files for images and texts are inconsistent!")
       print("Amount of image files: {}".format(len(img_array)))
       print("Amount of text files: {}".format(len(txt_array)))

       # End function if above error occurs
       return None
    
    train_img, test_img, train_txt, test_txt = train_test_split(img_array, txt_array, test_size=test_section, random_state=42)
 
    for file in train_img:
        temp = file[0]
        print(temp)
        input_path = os.sep.join([image_dir,temp])
        print(input_path)
        output_path = os.sep.join([target_dir,"images","train"])
        print(output_path)
        os.makedirs(output_path, exist_ok=True)
        shutil.copy(input_path,output_path)
    
    for file in test_img:
        temp = file[0]
        print(temp)
        input_path = os.sep.join([image_dir,temp])
        print(input_path)
        output_path = os.sep.join([target_dir,"images","val"])
        print(output_path)
        os.makedirs(output_path, exist_ok=True)
        shutil.copy(input_path,output_path)

    for file in train_txt:
        temp = file[0]
        print(temp)
        input_path = os.sep.join([txt_dir,temp])
        print(input_path)
        output_path = os.sep.join([target_dir,"labels","train"])
        print(output_path)
        os.makedirs(output_path, exist_ok=True)
        shutil.copy(input_path,output_path)

    for file in test_txt:
        temp = file[0]
        print(temp)
        input_path = os.sep.join([txt_dir,temp])
        print(input_path)
        output_path = os.sep.join([target_dir,"labels","val"])
        print(output_path)
        os.makedirs(output_path, exist_ok=True)
        shutil.copy(input_path,output_path)



     